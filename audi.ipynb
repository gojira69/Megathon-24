{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub\n",
    "!apt-get install ffmpeg -y\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydub import AudioSegment\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "asr_pipeline = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-medium\", device=-1)\n",
    "asr_pipeline.model.config.forced_decoder_ids = asr_pipeline.tokenizer.get_decoder_prompt_ids(language=\"en\", task=\"transcribe\")\n",
    "\n",
    "audio_dir = \"/content/drive/MyDrive/audiototext/audiomp3\"\n",
    "\n",
    "# Convert MP3 files to WAV format\n",
    "for file in os.listdir(audio_dir):\n",
    "    if file.endswith(\".mp3\"):\n",
    "        mp3_path = os.path.join(audio_dir, file)\n",
    "        wav_path = os.path.join(audio_dir, os.path.splitext(file)[0] + \".wav\")\n",
    "        audio = AudioSegment.from_mp3(mp3_path)\n",
    "        audio.export(wav_path, format=\"wav\")\n",
    "        print(f\"Converted {file} to {wav_path}\")\n",
    "\n",
    "# Filter for WAV files only\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
    "\n",
    "# Split files into train and test sets\n",
    "train_files, test_files = train_test_split(audio_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to transcribe audio files\n",
    "def transcribe_files(file_list):\n",
    "    transcriptions = []\n",
    "    for audio_file in file_list:\n",
    "        audio_path = os.path.join(audio_dir, audio_file)\n",
    "        audio, _ = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "        # Perform ASR on the audio\n",
    "        transcription = asr_pipeline(audio)[\"text\"]\n",
    "        transcriptions.append({\"filename\": audio_file, \"transcription\": transcription})\n",
    "        print(f\"Processed {audio_file}: {transcription}\")\n",
    "    return transcriptions\n",
    "\n",
    "# Transcribe training and testing sets\n",
    "train_transcriptions = transcribe_files(train_files)\n",
    "test_transcriptions = transcribe_files(test_files)\n",
    "\n",
    "# Convert transcriptions to DataFrames\n",
    "df_train = pd.DataFrame(train_transcriptions)\n",
    "df_test = pd.DataFrame(test_transcriptions)\n",
    "\n",
    "# Save CSV and TXT files\n",
    "df_train.to_csv(\"/content/drive/MyDrive/audiototext/train_transcriptions.csv\", index=False)\n",
    "df_test.to_csv(\"/content/drive/MyDrive/audiototext/test_transcriptions.csv\", index=False)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/audiototext/train_transcriptions.txt\", \"w\") as f:\n",
    "    for index, row in df_train.iterrows():\n",
    "        f.write(f\"{row['filename']}: {row['transcription']}\\n\")\n",
    "\n",
    "with open(\"/content/drive/MyDrive/audiototext/test_transcriptions.txt\", \"w\") as f:\n",
    "    for index, row in df_test.iterrows():\n",
    "        f.write(f\"{row['filename']}: {row['transcription']}\\n\")\n",
    "\n",
    "print(\"Training and testing transcriptions saved to train_transcriptions.csv, test_transcriptions.csv, train_transcriptions.txt, and test_transcriptions.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
